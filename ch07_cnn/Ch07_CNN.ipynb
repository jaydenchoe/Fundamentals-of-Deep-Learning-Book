{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch07_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaydenchoe/Fundamentals-of-Deep-Learning-Book/blob/master/ch07_cnn/Ch07_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeaHrLDY-CGK",
        "outputId": "69fe96bc-57f4-4aea-9a0a-93b809617599"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "\n",
        "# For reproducability\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff99e17be90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcXY8th9HNtG"
      },
      "source": [
        "# Full Description of the Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFxF_YwD5nj1"
      },
      "source": [
        "layer = nn.Conv2d(in_channels = 3,\n",
        "                  out_channels = 64,\n",
        "                  kernel_size = (5, 5),\n",
        "                  stride = 2,\n",
        "                  padding = 1\n",
        "                  )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1qszT3IHYnu"
      },
      "source": [
        "# Closing the Loop on MNIST with Convolutional Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiY2RbGn8GH8"
      },
      "source": [
        "class MNISTConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNISTConvNet, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 5, padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, 5, padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(7*7*64, 1024),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(1024, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    return self.fc1(x)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iujZwA469xZi"
      },
      "source": [
        "trainset = MNIST('.', train=True, download=True,\n",
        "                      transform=ToTensor())\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StpDFNUQ-KwC"
      },
      "source": [
        "lr = 1e-4\n",
        "num_epochs = 40\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MNISTConvNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtqvzP-e-doB",
        "outputId": "244b0a9e-b97c-4fc9-c98c-a649aa45e51d"
      },
      "source": [
        "for epochs in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  num_correct = 0\n",
        "  for inputs, labels in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(device))\n",
        "    loss = loss_fn(outputs, labels.to(device))\n",
        "    loss.backward()\n",
        "    running_loss += loss.item()\n",
        "    optimizer.step()\n",
        "    _, idx = outputs.max(dim=1)\n",
        "    num_correct += (idx == labels.to(device)).sum().item()\n",
        "  print('Loss: {} Accuracy: {}'.format(running_loss/len(trainloader),\n",
        "        num_correct/len(trainloader)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.296968074749782 Accuracy: 8.176972281449894\n",
            "Loss: 2.2871927965932817 Accuracy: 10.66950959488273\n",
            "Loss: 2.2768960858204728 Accuracy: 13.422174840085288\n",
            "Loss: 2.2656332020566405 Accuracy: 16.12366737739872\n",
            "Loss: 2.2538988386898406 Accuracy: 18.87313432835821\n",
            "Loss: 2.2400964536646537 Accuracy: 21.818763326226012\n",
            "Loss: 2.2241890898137204 Accuracy: 24.513859275053306\n",
            "Loss: 2.206875527082984 Accuracy: 26.886993603411515\n",
            "Loss: 2.1858361217258837 Accuracy: 29.32089552238806\n",
            "Loss: 2.1611066108573476 Accuracy: 31.601279317697227\n",
            "Loss: 2.1314344906857783 Accuracy: 33.833688699360344\n",
            "Loss: 2.0956502138678705 Accuracy: 35.80383795309169\n",
            "Loss: 2.052382417960462 Accuracy: 37.11727078891258\n",
            "Loss: 1.9991100091161504 Accuracy: 38.44136460554371\n",
            "Loss: 1.933697150587273 Accuracy: 39.817697228144986\n",
            "Loss: 1.854468691831967 Accuracy: 40.87846481876333\n",
            "Loss: 1.7600859479863507 Accuracy: 41.90618336886994\n",
            "Loss: 1.6509934996745226 Accuracy: 42.89658848614072\n",
            "Loss: 1.5301751141100803 Accuracy: 44.09061833688699\n",
            "Loss: 1.4042419938644621 Accuracy: 45.149253731343286\n",
            "Loss: 1.2778561868901446 Accuracy: 46.41684434968017\n",
            "Loss: 1.1611465680192528 Accuracy: 47.47867803837953\n",
            "Loss: 1.0553984708114983 Accuracy: 48.40191897654584\n",
            "Loss: 0.9651433885860037 Accuracy: 49.233475479744136\n",
            "Loss: 0.8882259192751415 Accuracy: 50.008528784648185\n",
            "Loss: 0.8244504113949692 Accuracy: 50.61300639658849\n",
            "Loss: 0.7680195129629391 Accuracy: 51.291044776119406\n",
            "Loss: 0.7234251002894282 Accuracy: 51.95948827292111\n",
            "Loss: 0.684267736129415 Accuracy: 52.36140724946695\n",
            "Loss: 0.6490920200975719 Accuracy: 52.872068230277186\n",
            "Loss: 0.619817655509723 Accuracy: 53.40085287846482\n",
            "Loss: 0.593970009385904 Accuracy: 53.72174840085288\n",
            "Loss: 0.5710601803463405 Accuracy: 54.075692963752665\n",
            "Loss: 0.5511661476608533 Accuracy: 54.32835820895522\n",
            "Loss: 0.5326771616999274 Accuracy: 54.66417910447761\n",
            "Loss: 0.5177279483916154 Accuracy: 54.87313432835821\n",
            "Loss: 0.5034366538847433 Accuracy: 55.014925373134325\n",
            "Loss: 0.4889185351571803 Accuracy: 55.32515991471215\n",
            "Loss: 0.4788352707460491 Accuracy: 55.360341151385924\n",
            "Loss: 0.4668296864990995 Accuracy: 55.624733475479744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvGyRcpjHds0"
      },
      "source": [
        "# Image Preprocessing Pipelines Enable More Robust Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmKyIloBBayF"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Normalize(mean = (0.1307,),\n",
        "                                 std = (0.3081,)\n",
        "                                 )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP5Ouft5EMq9"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "      transforms.RandomCrop(224),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ColorJitter(brightness=0,\n",
        "                             contrast=0,\n",
        "                             saturation=0,\n",
        "                             hue=0),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = (0.1307,),\n",
        "                           std = (0.3081,)\n",
        "                           )\n",
        "      ])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjQVxpPcHjou"
      },
      "source": [
        "# Accelerating Training with Batch Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgYLsCHEifT"
      },
      "source": [
        "layer = nn.BatchNorm2d(num_features=32,\n",
        "                       eps=1e-05,\n",
        "                       momentum=0.1,\n",
        "                       affine = True,\n",
        "                       track_running_stats = True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDxMfYM9E7G4"
      },
      "source": [
        "layer = nn.BatchNorm1d(num_features=32)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gesWMONHpQJ"
      },
      "source": [
        "#Group normalization for memory constrained learning tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz9PlSftFlkX"
      },
      "source": [
        "layer = nn.GroupNorm(num_groups=1,\n",
        "                     num_channels=32)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ2VMts4Hu1_"
      },
      "source": [
        "#Building a Convolutional Network for CIFAR-10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlYhhUElFmtp"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(9216, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128,10),\n",
        "            nn.BatchNorm1d(10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        return self.block2(x)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRF37tRGl-X"
      },
      "source": [
        "# Building a residual network with superhuman vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stu0eJ9cGo84"
      },
      "source": [
        "from torchvision.models import resnet34\n",
        "\n",
        "model = resnet34()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gNBxSXEG9Q_"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_layers, out_layers, downsample=None):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_layers, out_layers,\n",
        "                           kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(out_layers)\n",
        "    self.conv2 = nn.Conv2d(out_layers, out_layers,\n",
        "                           kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_layers)\n",
        "    self.downsample = downsample\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, inp):\n",
        "    # Residual block\n",
        "    out = self.conv1(inp)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample:\n",
        "      inp = self.downsample(inp)\n",
        "\n",
        "    # Shortcut connection\n",
        "    out += inp\n",
        "    return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9zt70bFHACP"
      },
      "source": [
        "downsample = nn.Sequential(\n",
        "      nn.Conv2d(64, 128, kernel_size=1, stride=1, bias=False),\n",
        "      nn.BatchNorm2d(128)\n",
        "    )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYXdO6ptHCh_"
      },
      "source": [
        "class ResNet34(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNet34, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, kernel_size=7,\n",
        "                stride=2, padding=3, bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,\n",
        "                   stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "    # Note that each ResidualBlock has 2 conv layers\n",
        "    # 3 blocks in a row, 6 conv layers\n",
        "    self.comp1 = nn.Sequential(\n",
        "      ResidualBlock(64, 64),\n",
        "      ResidualBlock(64, 64),\n",
        "      ResidualBlock(64, 64)\n",
        "    )\n",
        "\n",
        "    # 4 blocks in a row, 8 conv layers\n",
        "    downsample1 = nn.Sequential(\n",
        "      nn.Conv2d(64, 128, kernel_size=1,\n",
        "             stride=1, bias=False),\n",
        "      nn.BatchNorm2d(128)\n",
        "    )\n",
        "    self.comp2 = nn.Sequential(\n",
        "      ResidualBlock(64, 128, downsample=downsample1),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128)\n",
        "    )\n",
        "\n",
        "    # 6 blocks in a row, 12 conv layers\n",
        "    downsample2 = nn.Sequential(\n",
        "      nn.Conv2d(128, 256, kernel_size=1, stride=1, bias=False),\n",
        "      nn.BatchNorm2d(256)\n",
        "    )\n",
        "    self.comp3 = nn.Sequential(\n",
        "      ResidualBlock(128, 256, downsample=downsample2),\n",
        "      ResidualBlock(256, 256),\n",
        "      ResidualBlock(256, 256),\n",
        "      ResidualBlock(256, 256),\n",
        "      ResidualBlock(256, 256),\n",
        "      ResidualBlock(256, 256),\n",
        "    )\n",
        "\n",
        "    # 3 blocks in a row, 6 conv layers\n",
        "    downsample3 = nn.Sequential(\n",
        "      nn.Conv2d(256, 512, kernel_size=1, stride=1, bias=False),\n",
        "      nn.BatchNorm2d(512)\n",
        "    )\n",
        "    self.comp4 = nn.Sequential(\n",
        "      ResidualBlock(256, 512, downsample=downsample3),\n",
        "      ResidualBlock(512, 512),\n",
        "      ResidualBlock(512, 512)\n",
        "    )\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    # ImageNet classifier: 1000 classes\n",
        "    self.fc = nn.Linear(512, 1000)\n",
        "\n",
        "  def forward(self, inp):\n",
        "    out = self.conv1(inp)\n",
        "\n",
        "    out = self.comp1(out)\n",
        "    out = self.comp2(out)\n",
        "    out = self.comp3(out)\n",
        "    out = self.comp4(out)\n",
        "\n",
        "    out = self.avgpool(out)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}